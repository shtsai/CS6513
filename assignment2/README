These bash scripts are meant to help you debug your programs for HW2. 
Similar tests will be used in grading the assignment. 

Setting up the tester:
0. Recall that for submission, you should have a folder named your_netid, and within that folder, you should have 14 python files, for tasks 1-7, where for each task x, there is a file taskx.py which uses core Spark RDDs and a file taskx-sql.py which uses SparkSQL. 

1. Put the hw2tester.tar file in the same directory where you have the folder named your_netid.
2. Type: tar xvf hw2tester.tar 

You should run the scripts from within this same folder. 


To test an individual task, type:

./testtask.sh {tasknum} {your_netid}	(for core Spark)
	For example: ./testtask.sh 1 ecc290
./testtask-sql.sh {tasknum} {your_netid} (for SparkSQL)
	For example: ./testtask-sql.sh 1 ecc290


To test all tasks, both for core Spark and for SparkSQL, type:

./testall.sh {your_netid}
	For example: ./testall.sh ecc290


For each task that is run, the script will print to standard output whether you have passed or failed. 
If your code failed, a ".diff" file is created in the results/ folder, which tells you how the output your code produced differs from the solution key.
When "testall.sh" is run, a file named testresults.txt is produced which has the "passed" or "failed" status for each task.  

NOTE: As part of the assignment grade, you must also include output generated by your code. These testing scripts do not test whether you have included this output or not. 





